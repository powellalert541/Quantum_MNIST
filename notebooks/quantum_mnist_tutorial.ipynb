{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum MNIST Classification Tutorial\n",
    "\n",
    "This notebook provides a step-by-step walkthrough of building and training a hybrid quantum-classical neural network for MNIST digit classification.\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "We'll create a hybrid neural network that combines:\n",
    "- Classical neural network layers for preprocessing high-dimensional image data\n",
    "- Quantum circuits with trainable parameters for feature processing\n",
    "- Classical layers for final classification\n",
    "\n",
    "This architecture demonstrates how quantum computing can be integrated into machine learning pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from config import Config\n",
    "from data_utils import MNISTDataLoader, set_seed, get_device\n",
    "from models import SimplifiedHybridQNN, ClassicalNN, model_summary\n",
    "from train import Trainer, create_optimizer\n",
    "from visualize import (\n",
    "    plot_training_curves,\n",
    "    plot_confusion_matrix,\n",
    "    evaluate_model,\n",
    "    print_evaluation_results\n",
    ")\n",
    "from quantum_circuit import HybridQuantumCircuit\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Quantum Circuits\n",
    "\n",
    "Before training our model, let's understand what a quantum circuit looks like.\n",
    "\n",
    "A quantum circuit is composed of:\n",
    "- **Qubits**: The quantum analog of classical bits\n",
    "- **Quantum Gates**: Operations that manipulate qubit states\n",
    "- **Measurements**: Extracting classical information from quantum states\n",
    "\n",
    "Our hybrid circuit has two main parts:\n",
    "1. **Feature Map**: Encodes classical data into quantum states\n",
    "2. **Variational Circuit**: Contains trainable parameters (like weights in neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and visualize a quantum circuit\n",
    "hybrid_circuit = HybridQuantumCircuit(\n",
    "    n_qubits=4,\n",
    "    feature_dim=4,\n",
    "    feature_reps=2,\n",
    "    var_reps=3\n",
    ")\n",
    "\n",
    "circuit = hybrid_circuit.create_circuit()\n",
    "print(f\"Quantum Circuit Information:\")\n",
    "print(f\"  Number of qubits: {circuit.num_qubits}\")\n",
    "print(f\"  Circuit depth: {circuit.depth()}\")\n",
    "print(f\"  Number of gates: {circuit.size()}\")\n",
    "print(f\"  Trainable parameters: {hybrid_circuit.get_num_parameters()}\")\n",
    "\n",
    "# Draw the circuit\n",
    "try:\n",
    "    fig = circuit.draw(output='mpl', fold=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not draw circuit: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "MNIST contains 28x28 pixel grayscale images of handwritten digits (0-9).\n",
    "\n",
    "For this tutorial, we'll use binary classification (distinguishing between two digits) because:\n",
    "- It trains faster on quantum simulators\n",
    "- It's easier to visualize and understand\n",
    "- The same principles apply to multi-class problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Configuration\n",
    "Config.DATASET_TYPE = 'binary'\n",
    "Config.BINARY_CLASS_A = 0\n",
    "Config.BINARY_CLASS_B = 1\n",
    "Config.BINARY_TRAIN_SIZE = 500\n",
    "Config.BINARY_TEST_SIZE = 100\n",
    "Config.BATCH_SIZE = 32\n",
    "Config.NUM_EPOCHS = 10\n",
    "\n",
    "print(f\"Training binary classifier: {Config.BINARY_CLASS_A} vs {Config.BINARY_CLASS_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_loader = MNISTDataLoader(\n",
    "    data_dir='../data',\n",
    "    batch_size=Config.BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader = data_loader.create_binary_classification_dataset(\n",
    "    class_a=Config.BINARY_CLASS_A,\n",
    "    class_b=Config.BINARY_CLASS_B,\n",
    "    train_size=Config.BINARY_TRAIN_SIZE,\n",
    "    test_size=Config.BINARY_TEST_SIZE\n",
    ")\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "data_loader.get_dataset_info(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Plot first 10 images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(images):\n",
    "        img = images[i].squeeze()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Total pixels: {images[0].numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Hybrid Quantum-Classical Model\n",
    "\n",
    "Our hybrid model architecture:\n",
    "\n",
    "```\n",
    "Input (784 pixels)\n",
    "    ↓\n",
    "Classical Preprocessing (784 → 128 → 32 → 4)\n",
    "    ↓\n",
    "Quantum Circuit (4 qubits with trainable parameters)\n",
    "    ↓\n",
    "Classical Postprocessing (2 → 16 → 2 classes)\n",
    "    ↓\n",
    "Output (class predictions)\n",
    "```\n",
    "\n",
    "The classical preprocessing compresses the high-dimensional image data down to a size suitable for quantum processing. Currently, we're limited to a small number of qubits on simulators, so we use 4 qubits as a practical choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device\n",
    "device = get_device()\n",
    "\n",
    "# Create hybrid quantum model\n",
    "quantum_model = SimplifiedHybridQNN(\n",
    "    n_qubits=4,\n",
    "    n_classes=2\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nQuantum Hybrid Model:\")\n",
    "model_summary(quantum_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Classical Baseline for Comparison\n",
    "\n",
    "To understand if the quantum layer provides any advantage, we need a classical baseline. This is a standard fully-connected neural network with a similar number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classical baseline model\n",
    "classical_model = ClassicalNN(\n",
    "    hidden_sizes=[128, 64, 32],\n",
    "    n_classes=2\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nClassical Baseline Model:\")\n",
    "model_summary(classical_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the Models\n",
    "\n",
    "Now we'll train both models using the same hyperparameters and training procedure. This ensures a fair comparison.\n",
    "\n",
    "Training involves:\n",
    "1. Forward pass: Computing predictions\n",
    "2. Loss calculation: Measuring how wrong the predictions are\n",
    "3. Backward pass: Computing gradients\n",
    "4. Parameter update: Adjusting weights to reduce loss\n",
    "\n",
    "For quantum models, the trainable parameters are the rotation angles in the quantum gates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Quantum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training for quantum model\n",
    "quantum_optimizer = create_optimizer(quantum_model, Config)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "quantum_trainer = Trainer(\n",
    "    model=quantum_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=quantum_optimizer,\n",
    "    device=device,\n",
    "    config=Config,\n",
    "    model_name='quantum_hybrid_notebook'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "quantum_history = quantum_trainer.train(Config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training for classical model\n",
    "classical_optimizer = create_optimizer(classical_model, Config)\n",
    "\n",
    "classical_trainer = Trainer(\n",
    "    model=classical_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=classical_optimizer,\n",
    "    device=device,\n",
    "    config=Config,\n",
    "    model_name='classical_baseline_notebook'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "classical_history = classical_trainer.train(Config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress\n",
    "\n",
    "Training curves help us understand:\n",
    "- How quickly the model learns\n",
    "- Whether the model is overfitting (training accuracy much higher than validation)\n",
    "- Whether we need to train longer or adjust hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quantum model training curves\n",
    "plot_training_curves(quantum_history)\n",
    "plt.suptitle('Quantum Hybrid Model Training', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classical model training curves\n",
    "plot_training_curves(classical_history)\n",
    "plt.suptitle('Classical Model Training', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Test Set\n",
    "\n",
    "Now let's evaluate both models on unseen test data to get an unbiased measure of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate quantum model\n",
    "quantum_results = evaluate_model(quantum_model, test_loader, device, n_classes=2)\n",
    "print_evaluation_results(quantum_results, \"Quantum Hybrid Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classical model\n",
    "classical_results = evaluate_model(classical_model, test_loader, device, n_classes=2)\n",
    "print_evaluation_results(classical_results, \"Classical Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrices\n",
    "\n",
    "Confusion matrices show us exactly which classes the model confuses. Diagonal elements are correct predictions, off-diagonal are errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum model confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    quantum_results['labels'],\n",
    "    quantum_results['predictions'],\n",
    "    class_names=[f'Digit {Config.BINARY_CLASS_A}', f'Digit {Config.BINARY_CLASS_B}']\n",
    ")\n",
    "plt.suptitle('Quantum Model Confusion Matrix', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical model confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    classical_results['labels'],\n",
    "    classical_results['predictions'],\n",
    "    class_names=[f'Digit {Config.BINARY_CLASS_A}', f'Digit {Config.BINARY_CLASS_B}']\n",
    ")\n",
    "plt.suptitle('Classical Model Confusion Matrix', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Comparison\n",
    "\n",
    "Let's directly compare the performance metrics of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Quantum Model': [\n",
    "        f\"{quantum_results['accuracy']*100:.2f}%\",\n",
    "        f\"{quantum_results['precision']:.4f}\",\n",
    "        f\"{quantum_results['recall']:.4f}\",\n",
    "        f\"{quantum_results['f1_score']:.4f}\"\n",
    "    ],\n",
    "    'Classical Model': [\n",
    "        f\"{classical_results['accuracy']*100:.2f}%\",\n",
    "        f\"{classical_results['precision']:.4f}\",\n",
    "        f\"{classical_results['recall']:.4f}\",\n",
    "        f\"{classical_results['f1_score']:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Hybrid Architecture**: We successfully integrated quantum circuits into a classical neural network using PyTorch and Qiskit.\n",
    "\n",
    "2. **Quantum Circuits**: The quantum component uses parameterized gates that are trained just like weights in classical neural networks.\n",
    "\n",
    "3. **Current Limitations**: Quantum simulators are computationally expensive, which is why we:\n",
    "   - Used only 4 qubits\n",
    "   - Trained on a subset of MNIST\n",
    "   - Focused on binary classification\n",
    "\n",
    "4. **Performance**: The quantum model may perform similarly to or slightly differently than the classical baseline. This is expected because:\n",
    "   - We're using simulators, not real quantum hardware\n",
    "   - The problem size is small (binary classification)\n",
    "   - Quantum advantage typically appears in specific problem types\n",
    "\n",
    "### Future Improvements:\n",
    "\n",
    "- Try different quantum circuit designs (ansatz)\n",
    "- Experiment with more qubits (when hardware allows)\n",
    "- Test on problems where quantum computing might excel\n",
    "- Use real quantum hardware instead of simulators\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "This project demonstrates the feasibility of hybrid quantum-classical machine learning. As quantum hardware improves, these techniques could potentially solve problems that are intractable for classical computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Experiment: Try It Yourself!\n",
    "\n",
    "Now that you understand the basics, try modifying the code:\n",
    "\n",
    "1. Change which digits to classify (e.g., 3 vs 8 instead of 0 vs 1)\n",
    "2. Adjust the number of training samples\n",
    "3. Modify the quantum circuit parameters\n",
    "4. Try multi-class classification (3+ classes)\n",
    "\n",
    "Use the cells below to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experiments here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
